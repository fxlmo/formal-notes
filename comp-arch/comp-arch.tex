%%=====================================================================================
%%
%%       Filename:  comp-arch.tex
%%
%%    Description:  A comprehensive list of notes from teaching block 1, year 1.
%%
%%        Version:  1.0
%%        Created:  16/12/18
%%
%%         Author:  Josh Felmeden (), nk18044@bristol.ac.uk
%%      Copyright:  Copyright (c) 2018, Josh Felmeden
%%
%%
%%=====================================================================================

% Preamble
\documentclass[11pt,a4paper,titlepage,dvipsnames,cmyk]{scrartcl}
\usepackage[english]{babel}
\typearea{12}

% Set indentation and line skip for paragraph
\setlength{\parindent}{0em}
\setlength{\parskip}{1em}
\usepackage[margin=2cm]{geometry}
\addtolength{\textheight}{-1in}
\setlength{\headsep}{.5in}

% Headers setup
\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{Introduction to Computer architecture: The Comprehensive Notes}
\rhead{Josh Felmeden}
\usepackage{hyperref} 


% Listings
\usepackage[]{listings,xcolor} 
\lstset
{
    breaklines=true,
    tabsize=3,
    showstringspaces=false
}


\lstdefinestyle{Common}
{
    extendedchars=\true,
    language={[Visual]Basic},
    frame=single,
    %===========================================================
    framesep=3pt,%expand outward.
    framerule=0.4pt,%expand outward.
    xleftmargin=3.4pt,%make the frame fits in the text area. 
    xrightmargin=3.4pt,%make the frame fits in the text area.
    %=========================================================== 
    rulecolor=\color{Red}
}

\lstdefinestyle{A}
{
    style=Common,
    backgroundcolor=\color{Yellow!10},
    basicstyle=\small\color{Black}\ttfamily,
    keywordstyle=\color{Orange},
    identifierstyle=\color{Cyan},
    stringstyle=\color{Red},
    commentstyle=\color{Green}
}

\lstdefinestyle{B}
{
    style=Common,
    backgroundcolor=\color{Black},
    basicstyle=\scriptsize\color{White}\ttfamily,
    keywordstyle=\color{Orange},
    identifierstyle=\color{Cyan},
    stringstyle=\color{Red},
    commentstyle=\color{Green}
}

\usepackage[]{amsmath} 
\usepackage[]{booktabs} 
\usepackage[symbol]{footmisc} 
\renewcommand{\thefootnote}{\fnsymbol{footnote}}

% Title
\title{Introduction to Computer Architecture: The (almost) Comprehensive
Notes}
\date{2018\\ December}
\author{Josh Felmeden}

% Start document
\begin{document}
\maketitle

\tableofcontents
\newpage

\section{Integer representation and arithmetic}%
\label{sec:reallyboring}
First things first, we need to look at the ways that numbers are added together
(I chose to skip over how numbers are stored in the computer because I think
this is boring and if you need help with this then you really are beyond all
hope.). Ultimately, we've started with addition to start with, so we're going to
look at simple circuits for addition in a computer. By the way, if we have a
letter with a hat on (namely: $\hat x$), this means that it's a bit sequence
representing some integer $x$. This leaves us with this:
\begin{align*}
    \hat x \mapsto x \\
    \hat y \mapsto y \\
    \hat r \mapsto r
\end{align*}

Alongside this, we have the following relationship:
\begin{equation}
    r = x + y
\end{equation}

The question is, how do we take this and represent it using boolean algebra?
Well, we're going to try:
\begin{equation}
    \hat r = F(\hat x, \hat y)
\end{equation}

Where $F$ is some boolean expression. What this means is that the $+$ operator
has a similar result than $F$. What the bloody hell is this function? Let's have
a look.

It's actually not that bad. If we look at how humans do addition, we have:
\begin{align*}
    &\hat x = 1 \quad 0 \quad 7 \\
    + \quad &\hat y = 0 \quad 1 \quad 4 \\
        &\rule{60pt}{1pt} \\
           &c = 0 \quad 1 \quad 0 \\
           &\hat r = 1 \quad 2 \quad 1
\end{align*}
Where c is the carry (we also have 0 as a carry out here). The same thing can be
represented in binary:
\begin{align*}
    107_{10} = \quad &\hat x = 0 \quad 1 \quad 1 \quad 0 \quad 1 \quad 0 \quad 1 \quad
    1 \\
    + 14_{10} = \quad &\hat y = 0 \quad 0 \quad 0 \quad 0 \quad 1 \quad 1 \quad 1
    \quad 0 \\
      &\rule{150pt}{1pt} \\
      &c = 0 \quad 0 \quad 0 \quad 1 \quad 1 \quad 1 \quad 0 \quad 0 \\
      &\hat r = 0 \quad 1 \quad 1 \quad 1 \quad 1 \quad 0 \quad 0 \quad 1
\end{align*}

Now, we're going to create a really simple algorithm (it's going to be called
ADD), and is going to look like $\text{ADD}(\hat x, \hat y, n, b, ci)$, where b
is the base, ci is the carry in and n is the length of x and y. We would then
have the algorithm as follows:
\begin{lstlisting}[style=B]
for i = 0 to (n-1)
    r(i) += (x(i) + y(i) + c(i)) mod b
    if(x(i) + y(i) + c(i) < b)
        c(i+1) = 0
    else
        c(i+1) = 1
    end if
next
co = c(n)
return r, co
\end{lstlisting}

Let's step through this algorithm:
\begin{gather*}
    \hat x = \langle 7, 0, 1 \rangle \mapsto 107_{10} \\
    \hat y = \langle 4, 1, 0 \rangle \mapsto 14_{10} \\
    n = 3, \ b = 10, \ ci = 0, \\
    \text{ADD}(\hat x, \hat, y, 3, 10, 0)
\end{gather*}

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        i & $\hat x_i, \ \hat y_i, \ c_i$ & $\hat x_i + \hat y_i + c_i$ &
        $c_{i+1}, \hat r_i$\\
        \hline
        0 & 7, 4, 0 & 11 & 1, 1 \\
        \hline
        1 & 0, 1, 1 & 2 & 0, 2 \\
        \hline
        2 & 1, 0, 0 & 1 & 0, 1 \\
        \hline
    \end{tabular}
\end{center}

Where the at the end, $\hat r = \langle 1 2 1 \rangle$, as stated by the last
column.

In the algorithm above, the bit inside the for loop can be represented by $F_i$,
where it has the inputs $\hat x_i, \hat y_i, \hat c_i$ and has outputs 
$\hat r_i,c_{xi+1}$. We don't have to know what the function is, but we can write
down their behaviour. Because we know what should happen\footnote[1]{These tables
took so damn long please appreciate them}.

\begin{center}
    \begin{tabular}{|c c c|c|c|}
        \hline
        $c_i$ & $\hat x_i$ & $\hat y_i$ & $c_{i+1}$ & $\hat r_i$ \\
        \hline
        0 & 0 & 0 & 0 & 0 \\
        \hline
        0 & 0 & 1 & 0 & 1 \\
        \hline
        0 & 1 & 0 & 0 & 1 \\
        \hline
        0 & 1 & 1 & 1 & 0 \\
        \hline
        1 & 0 & 0 & 0 & 1 \\
        \hline
        1 & 0 & 1 & 1 & 0 \\
        \hline
        1 & 1 & 0 & 1 & 0 \\
        \hline
        1 & 1 & 1 & 1 & 1 \\
        \hline
    \end{tabular}
\end{center}

We know that $c_{i+1} = (\hat x_i \wedge \hat y_i) \vee (\hat x_i \wedge c_i)
\vee (\hat y_i \wedge c_i)$ and we ALSO know that $\hat r_i = \hat x_i \oplus
\hat y_i \oplus c_i$. Thus ends the middle bit of the algorithm, so now let's
look at the whole algorithm.

Basically, we just string together a load of the components that we had before.
That is to say, if we have $n$ bits, we need $n$ of those adders. Each adder
takes 3 inputs: the $n$th digit of $x$ and $y$, and a carry, which comes from
the $n-1$th adder. At the very end of the block, we get a carry out.
Additionally, at each adder, we get the $n$th digit of the result ($\hat r$).
This could kinda be obvious, but if you think that, shut up. It's interesting to
know that there is not computation other than that in the adders. This is called
a \textbf{ripple carry adder} and it relates to the loop within the algorithm.
Each one of the `components' that I was talking about is called a \textbf{full
adder}, but we might replace this with a half adder later (we definitely will).
We can write this whole thing in forms of boolean expressions now, so there you
go.

Before we finish with these bad boys, we need to explore some examples. Let's
look at when $\hat x = 1111$ and $\hat y = 0001$. If we want to add those
together, we get:
\begin{align*}
    &\hat x = 1 \quad 1 \quad 1 \quad 1 \mapsto 15_{10} \\
    + \quad &\hat y = 0 \quad 0 \quad 0 \quad 1 \mapsto 1_{10} \\
         &\rule{75pt}{1pt}\\
         &c = 1 \quad 1 \quad 1 \quad 0 \quad (c_o = 1)\\
    &\hat r = 0 \quad 0 \quad 0 \quad 0
\end{align*}

This is an issue because $15 + 1$ is NOT 0, and this is an error. We use the
carry out to determine whether there has been an error, because if there is a
carry out of 1, then there is clearly an error.

If we look at the case when we use all 1s with 2's complement (i.e. -1), and we
add 1 to it, happily we get 0. We have the same behaviour, but the result is
right. Unfortunately, we lost the functionality of the 1 as a carry out error
marker, because there are still the possibility for errors. Take, for example,
$x = 0111_2 \mapsto 7_{10}$ and $y = 0001_2 \mapsto 1_{10}$. When we add these in
binary, we end up with $1000_2 \mapsto -8_{10}$, with a carry out of 0. This is
not the right answer. There is kind of a way around this, where if there are a
mismatch between the first bit of x and y and the first (most significant) bit
of c and r. Formally then, the sign of $\hat x, \hat y, \hat r$ should not end
up with a $+ve + +ve \rightarrow -ve$ and vice versa. This is known as a
\textit{carry error}. 

With the errors that we have detected, we should be responsible people and tell
the programmers that an error has occurred by medium of a flag, or even CORRECT
the error, (but we can't do that because we have a fixed number of bits).

\section{Transistors}%
\label{sec:Transistors}

An electrical current is a \textit{flow} of electrons. A capacitor (such as a
battery) works by having \textbf{free electrons} move from high to low
potential. A \textit{conductivity} rating says how easily electrons can move.
\begin{itemize}
    \item A conductor has \textit{high conductivity} and allows electrons to
        move easily.
    \item An insulator has low conductivity and does \textbf{not} allow
        electrons to move easily.
\end{itemize}

Silicon is a DOPE material, because there's lots of it, and it's also pretty
cheap. It's also inert (which means boring aka doesn't react in weird ways)
because it's stable enough to not react in weird ways with normal things
\textit{and} it can be doped with a donor material, which will allow us to
construct the materials with the precise sub atomic properties that we want.

The result of this is a semi conductor. `What is this?' I hear you ask. Well,
it's kind of a conductor and kind of not. If this isn't any clearer, here's a
little more info:
\begin{itemize}
    \item A \textbf{P-type} semi-conductor has extra holes, while
        \textbf{N-type} has extra electrons.
    \item if we sandwich together the P and N type layers together, the result
        is that the electrons can only move in one way. For example, from N to
        P, but not vice versa.
\end{itemize}

Back in the olden days, we used to have a vacuum tube, because when the filament
heats up, the electrons are produced into the vacuum, which are then attracted
by the plate. They're pretty reliable generally, but they fail a fail bit during
power on and off. It's also where we get the term \textit{bug} from, since a
literal bug could cause failures in this thing.

\subsection{MOSFETs}%
\label{sub:MOSFETs}
We're now going to look at MOSFETS gang. MOSFET stands for Metal Oxide
Semi-conductor Field Effect Transistor. Yeah, really. That's why there is an
abbreviation for it. A MOSFET has 3 parts, a \textbf{source}, \textbf{drain},
and a \textbf{gate}. The source and the drain are terminals, and the gate is
what controls the flow of electrons between the source and the drain. That, on a
simple level, is that, because any further description is pretty freaking
complicated and is not necessary for this course.

\subsubsection{N-MOSFET}%
\label{ssub:N-MOSFET}
An N-MOSFET (or negative MOSFET) is constructed from \textbf{n-type}
semiconductor terminals inside a p-type body. This means that applying a
potential difference to
the gate \textit{widens} the conductive channel, meaning that the source and
drain are connected, and the transistor is activated. Removing the potential
difference
\textit{narrows} the conductive channel and the source and the drain are
disconnected. Simply, \textbf{p.d. = current flows through, else block}.

\subsubsection{P-MOSFET}%
\label{ssub:P-MOSFET}
A P-MOSFET (or positive MOSFET) is constructed from \textbf{p-type}
semiconductor terminals inside an n-type body. Applying a potential difference to the gate
\textit{narrows} the conductive channel, meaning that no current can flow, and
removing the potential difference allows the current to flow. Simply, \textbf{p.d. = no
current flowing, else there is current flowing}. Also, p-types have a funny
looking bobble hat in a diagram.

These MOSFETS aren't normally used in isolation, and they are used in CMOS
cells, which stands for complimentary metal oxide semiconductor. We combine 2 of
one type and one of the other into one body, namely, the CMOS cell. It's pretty
useful because they work in complimentary ways, but there is also little
leakage, or \textbf{static} power consumption. It only consumes power during the
switching action (\textbf{dynamic} consumption).

\subsection{Manufacture}%
\label{sub:Manufacture}
It's necessary to be able to construct these bad boys in batch, because
otherwise we wouldn't be able to make big machines out of them because we need
so many of them. What we do is:
\begin{enumerate}
    \item Start with a clean, prepared \textbf{wafer}.
    \item Apply a layer of \textbf{substrate} material, such as a metal or a
        semi conductor.
    \item Apply a layer of photoresist. This material reacts differently when it
        is exposed to light.
    \item To do this, we expose a precise negative (or \textit{mask}) of design
        that hardens the exposed photoresist.
    \item Wash away the unhardened photoresist.
    \item Etch away the uncovered substrate.
    \item Strip away the hardened photoresist.
\end{enumerate}

Remember that this algorithm repeats over and over in order to make the result 3
dimensions, rather than 2. Regularity is a huge advantage because we can
manufacture a great number of similar components in a layer using a single
process. The feature size (it's 90nm big) relates to the resolution of the
process.

These components are USELESS in this form, so they're packaged before use, which
protects against damage, including heat sinks and an interface between the
component and the outside world using pins bonded to internal inputs and
outputs.

So, while MOSFETs are pretty great, there are down sides. Designing
complex functionality using transistors alone is really hard because
transistors are simply \textit{too} low level. We can address this problem
by repackaging groups of transistors into logic gates, since logic gates
are ordered logic gates such that we get certain functionality. Pretty
cool right? It's like nerdy Lego.

\section{Logic Gates}%
\label{sec:logic-gates}
If we form a \textbf{pull-up network} of P-MOSFET transistors, connected
to $V_{dd}$ (which is the high voltage rail), and a \textbf{pull-down
network} of N-MOSFETs, connected to $V_{ss}$ (the low voltage rail), and
assume that the power rails are everywhere:
\begin{align*}
    V_{ss} &= 0V \approx 0 \\
    V_{dd} &= 5V \approx 1
\end{align*}

We can then describe the operation of each logic gate using a truth table.

\subsection{NAND gate}%
\label{sub:nand}
% Insert picture of a nand gate I think
If both x and y are 0 (connected to $V_{ss}$), then:
\begin{enumerate}
    \item Both top P-MOSFETs will be connected.
    \item Both botton N-MOSFETs will be disconnected.
    \item r (the output) will be connected to $V_{dd}$
\end{enumerate}

If x is 1 and y is 0, then:
\begin{enumerate}
    \item The right most P-MOSFET will be connected.
    \item The upper-most N-MOSFET will be disconnected.
    \item r will be connected to $V_{dd}$
\end{enumerate}

If x is 0 and y is 1, then:
\begin{enumerate}
    \item The left most P-MOSFET will be connected.
    \item The lower-most N-MOSFET will be disconnected.
    \item r will be connected to $V_{dd}$
\end{enumerate}

Finally, if both x and y are 1, then:
\begin{enumerate}
    \item Both top P-MOSFETs will be disconnected.
    \item Both bottom N-MOSFETs will be connected.
    \item r will be connected to $V_{ss}$
\end{enumerate}

\subsection{NOR gate}%
\label{sub:nor}
% Insert picture of a nor gate
If both x and y are 0, then:
\begin{enumerate}
    \item Both top P-MOSFETs will be connected.
    \item Both bottom N-MOSFETs will be disconnected.
    \item r will be connected to $V_{dd}$
\end{enumerate}

If x is 1 and y is 0, then:
\begin{enumerate}
    \item The upper-most P-MOSFET will be disconnected
    \item the left-most N-MOSFET will be connected.
    \item r will be connected to $V_{ss}$
\end{enumerate}

If x is 0 and y is 1, then:
\begin{enumerate}
    \item The lower-most P-MOSFET will be disconnected.
    \item The right-most N-MOSFET will be connected.
    \item r will be connected to $V_{ss}$.
\end{enumerate}

If both x and y are 1, then:
\begin{enumerate}
    \item Both top P-MOSFETs will be disconnected.
    \item Both botton N-MOSFETs will be connected.
    \item r will be connected to $V_{ss}$.
\end{enumerate}

\subsection{Physical limitations}%
\label{sub:Physical limitations}
There are, of course, some physical limitations that we haven't discussed
yet. There are two classes of delay (often described as
\textbf{propagation delay}), that will dictate the time between change to
some input and corresponding change in an output. These are:
\begin{itemize}
    \item \textbf{Wire delay:} This relates to the time taken for the
        current to move through the conductive wire from one point to
        another.
    \item \textbf{Gate delay:} This relates to the time taken for the
        transistors in each gate to switch between the connected and
        disconnected states
\end{itemize}
Normally, the gate delay is more than wire delay, and both relate to the
implementations. Gate delay is the fault of the properties of the
transistors used, and wire delay to the properties of the wire.

\textbf{Critical path} is the longest sequential delay possible in some
combinatorial logic. Basically, the worst case scenario in a given logic
circuit.

Ideally, we'd get a perfect digital on/off graph of the response, while in
reality, we get a more curved graph. It would also make sense to have 1
and 0 as a threshold, rather than a definitive voltage. This fuzzy
representation allows for some inaccuracies that are unavoidable with this
physical implementation.

Including gate delay gives us a \textit{dynamic} view computation. We're
gonna kind of ignore wire delay for the moment and arbitrarily choose some
delays for the gates:
\begin{enumerate}
    \item NOT: 10ns
    \item AND: 20ns
    \item OR: 20ns
\end{enumerate}

If we then did some computation, we could see the output changing after we
switch x from 0 to 1 and keep y as 1. If we're using an XOR gate, then it
would take 50ns to completely change to 0 (since x and y are both 1, hence
x XOR y = 0).

It is cool to use \textit{3-stage logic}, using an extra value:
\begin{itemize}
    \item 0 is false
    \item 1 is true
    \item Z is \textbf{high impedance}
\end{itemize}

High impedance is the null value, so we can allow a wire to be
disconnected.

If we have two inputs connected to an output, you can have some weird
results where the two inputs are in conflict with the other. The way to
fix this is to have some enable switch on the two inputs to the output, so
we don't get any inconsistencies.

Here are some more definitions:
\begin{itemize}
    \item \textbf{fan-in} is used to describe the number of inputs to a
        given gate.
    \item \textbf{fan-out} is used to describe the number of inputs (or
        \textit{other} gates) the output of a given gate is connected to.
\end{itemize}

\section{Combinatorial Logic}%
\label{sec:combinatorial}

The logic gates that we've discussed already are higher level than the
transistors that we started off with. Armed with these new logic gates, we
can move onto \textit{actual} high level components. We want components
that are closer to what we can actually do things with.

Thus far, we've just looked at various ways of writing the same things;
having moved from the completely abstract pencil and paper, to the
implementation of logic gates and NAND-boards.

\subsection{Design patterns}%
\label{sub:patterns}
There are a number of design patterns that we can take:

\subsubsection{Decomposition}%
\label{ssub:Decomposition}

Divide and conquer, take some complicated design, and break it down into
simpler and more manageable parts.

\subsubsection{Sharing}%
\label{ssub:Sharing}

We can replace two AND gates that exist in some design with a single AND
gate, using the same gate from the usage points.  It makes sense because
the output will always be the same.

\subsubsection{Isolated Replication}%
\label{ssub:isolated}

Say we have a 2 input AND gate, and we want a 2-input \textit{m}-bit AND
gate, which is simply a replication of 2-input, 1-bit AND gates, then we
are going to have \textit{m}-bits of the AND gate. We're also saying that
they are operating in parallel, and that each bit does not affect the
neighbouring bits.

\subsubsection{Cascaded Replication}%
\label{ssub:cascaded}

Using the same example as before, instead of using \textit{m} AND gates,
we want something like this:
\begin{alignat*}{4}
    r &= & &x_0 \wedge x_1   &&\ \wedge \ & &x_2 \wedge x_3 \\
      &= (& &x_0 \wedge x_1) &&\wedge \ (& &x_2 \wedge x_3)
\end{alignat*}

You can also write that like this:
\begin{equation*}
    r = \bigwedge^{n-1}_{i=0} x_i
\end{equation*}

It's different from isolated replication, because the and gates are
entirely isolated from one another.

\subsection{Mechanical Derivation}%
\label{sub:mechanical}
In every case, the process is the same. We want to be able to process some
truth table and get something that will work (with a boolean expression).
So, let's let $T_i$ denote the $j$th input for $0 \le j < n$, and let $O$
denote the single output.

\begin{enumerate}
    \item Find a set $T$ such that $i \in T$ iff. $O = 1$ in the $i$th row
        of the truth table.
    \item For each $i \in T$, form a term $t_i$ by ANDing together all the
        variables while following two rules:
        \begin{enumerate}
            \item if $T_j = 1$ in the $i$th row, then we use $T_j$ as is,
                but
            \item If $T_j = 0$ in the $i$th row, then we use $-T_j$
        \end{enumerate}
    \item An expression implementing this function is then formed by ORing
        all of the terms together:
        \begin{equation*}
            e = \bigvee_{i \in T} t_i
        \end{equation*}
\end{enumerate}

Let's consider the example of deriving an expression for XOR:
\begin{equation*}
    r = f(x,y) = x \oplus y
\end{equation*}

This is a function described by the following table:
\begin{center}
    \begin{tabular}{|c c|c|}
        \hline
        $x$ & $y$ & $r$ \\
        \hline
        0 & 1 & 1 \\
        \hline
        1 & 0 & 1 \\
        \hline
        1 & 1 & 0 \\
        \hline
    \end{tabular}
\end{center}

\subsection{Karnaugh Map}%
\label{sub:karnaugh}

The simple algorithm for creating a Karnaugh map is as follows:
\begin{enumerate}
    \item Draw a rectangular ($p \times 1$) element grid:
    \begin{enumerate}
        \item $p = q = 0 (mod 2)$, and
        \item $p \cdot q = 2^n$
    \end{enumerate}
    \item Fill the grid elements with the output that corresponds to
        inputs for that row and column.
    \item Cover rectangular groups of
        adjacent 1 elements which are of total size $2^n$ for some group
        $m$, groups can `wrap around' if you like, so they can go over
        edges of the grid and overlap.
    \item Translate each group into a single term in some SoP form Boolean
        expression, where
    \begin{enumerate}
        \item bigger groups
        \item less groups
    \end{enumerate}
    mean a simpler expression.
\end{enumerate}

The basic idea is that we don't count up as per normal in binary, but we
actually count up by changing one binary digit at a time. You then group
them, and the groups have to be adjacent (but they can't form a kind of L
shape). After this, it's easy to group them into some format.

\subsection{Building blocks}%
\label{sub:blocks}

There are two more blocks that we're going to look at now:
\begin{enumerate}
    \item \textbf{Multiplexer}
        \begin{itemize}
            \item It has $m$ inputs,
            \item 1 output and
            \item uses a ($\log_2(m)$)-bit control signal input to choose
                which input is connected to the output.
        \end{itemize}
    \item \textbf{Demultiplexer}
        \begin{itemize}
            \item It has 1 input,
            \item $m$ outputs and
            \item uses a ($\log_2(m)$)-bit control signal to choose which
                output is connected to the input
        \end{itemize}
\end{enumerate}

Remember that the inputs and outputs are $n$ bits, but they obviously have
to match up. The connection that is made is continuous, because both
components are \textit{combinatorial}.

\subsubsection{Multiplexer}%
\label{ssub:Multiplexer}
The behaviour of a 2-input, 1-bit multiplexer is as follows:
\begin{equation*}
    r = (\neg \ c \wedge x) \vee (c \wedge y)
\end{equation*}

It can be more clearly represented by this table:
\begin{center}
    \begin{tabular}{|c c c|c|}
        \hline
        c & x & y & r \\
        \hline
        0 & 0 & ? & 0 \\ \hline
        0 & 1 & ? & 1 \\ \hline
        1 & ? & 0 & 0 \\ \hline
        1 & ? & 1 & 1 \\ \hline
    \end{tabular}
\end{center}


\subsubsection{Demultiplexer}%
\label{ssub:Demultiplexer}

The behaviour of a 2-output, 1-bit demultiplexer is as follows:
\begin{align*}
    r_0 &= \neg \ c \wedge x \\
    r_1 &- c \wedge x
\end{align*}

It can be more clearly represented in this table:
\begin{center}
    \begin{tabular}{|c c|c c|}
        \hline
        $c$ & $x$ & $r_1$ & $r_0$ \\ \hline
        0 & 0 & ? & 0 \\ \hline
        0 & 1 & ? & 1 \\ \hline
        1 & 0 & 0 & ? \\ \hline
        1 & 1 & 1 & ? \\ \hline
    \end{tabular}
\end{center}

Multiplexers can be used to for isolated replication. If we line up 4
multiplexers, we get a control signal in to choose between two choices,
and we get one of those out, meaning that we end up with a 4-bit output.
We can scale this in the same way as before and use the \textit{cascaded}
pattern, meaning that they interact with one another. We now need a 2-bit
control signal however, because in the other design, each multiplexer uses
the same control signal.

Building on this idea, we can look at two more components:
\begin{enumerate}
    \item Half adder
        \begin{itemize}
            \item Has 2 inputs, $x$ and $y$,
            \item Computes the 2-bit result $x + y$
            \item Has 2 outputs: a sum $s$ and a carry out $co$ (which are
                the least significant bit and the most significant bit of
                the result)
        \end{itemize}
    \item Full adder
        \begin{itemize}
            \item Has 3 inputs: $x$, $y$, and a carry-in $ci$
            \item Computes the 2-bit result $x + y + ci$
            \item Has 2 outputs: a sum $s$ and a carry out $co$ (which are
                the least significant bit and the most significant bit of
                the result)
        \end{itemize}
\end{enumerate}

\subsection{Half adder}%
\label{sub:half}
The behaviour of the half adder looks like this:
\begin{center}
    \begin{tabular}{|c c|c|c|}
        \hline
        $x$ & $y$ & $co$ & $s$ \\ \hline
    \end{tabular}
\end{center}

And can be displayed by the following equations:
\begin{align*}
    co &= x \wedge y \\
    s &= x \oplus y
\end{align*}

\subsection{Full adder}%
\label{sub:full}
The behaviour of a full adder looks like this:
\begin{center}
    \begin{tabular}{|c c c|c|c|}
        \hline
        $ci$ & $x$ & y & $co$ & $s$ \\ \hline
        0 & 0 & 0 & 0 & 0 \\ \hline
        0 & 0 & 1 & 0 & 1 \\ \hline
        0 & 1 & 0 & 0 & 1 \\ \hline
        0 & 1 & 1 & 1 & 0 \\ \hline
        1 & 0 & 0 & 0 & 1 \\ \hline
        1 & 0 & 1 & 1 & 0 \\ \hline
        1 & 1 & 0 & 1 & 0 \\ \hline
        1 & 1 & 1 & 1 & 1 \\ \hline
    \end{tabular}
\end{center}

And can be displayed by the following equations:
\begin{align*}
    co &= (x \wedge y) \vee (x \wedge ci) \vee (y \wedge ci) \\
       &= (x \wedge y) \vee ((x \oplus y) \wedge ci) \\
    s &= x \oplus y \oplus ci
\end{align*}

A full adder is kind of like two half adders put together in a nice way.

There is a circuit for the full adder that allows us to implement the
cascading design choice to replicate the $n$-bit addition; cascading
because of the carries that we have are \textit{cascaded} into one
another. It might not be immediately clear that it's cascaded when we
initially looked at it, but now as we look at it from a higher value, then
we can clearly see that it is indeed cascaded.


Moving onto equality comparators, we have 2 final building blocks:
\begin{enumerate}
    \item An equality comparator
        \begin{itemize}
            \item Has 2 inputs: $x$ and $y$,
            \item computes the 1 output as:
                \begin{equation*}
                    r = \bigg \{
                   \begin{matrix}
                       1 & \text{if } $x = y$ \\
                       0 & \text{otherwise}
                   \end{matrix}
                \end{equation*}
        \end{itemize}
    \item A less-than comparator
        \begin{itemize}
            \item Has 2 inputs: $x$ and $y$,
            \item computes the 1 output as:
                \begin{equation*}
                    r = \bigg \{
                        \begin{matrix}
                            1 & \text{if } x < y \\
                            0 & \text{otherwise}
                        \end{matrix}
                \end{equation*}
        \end{itemize}
\end{enumerate}

All of the inputs and outputs are only 1 bit.

Even though we only have these two, we can do a lot of other comparators,
for example, we can get $x \neq y$ from passing the result of an equality
gate through a not gate.

\subsection{Equality comparator}%
\label{sub:equality}
The behaviour of the equality comparator is as follows:
\begin{equation*}
    r = \neg (x \oplus y)
\end{equation*}

And can be modelled by this table:
\begin{center}
    \begin{tabular}{|c c|c|}
        \hline
        $x$ & $y$ & $r$ \\ \hline
        0 & 0 & 1 \\ \hline
        0 & 1 & 0 \\ \hilne
        1 & 0 & 0 \\ \hline
        1 & 1 & 1 \\ \hline
    \end{tabular}
\end{center}

\subsection{Less-than comparator}%
\label{sub:less-than}

The behaviour of the less-than comparator can be modelled as follows:
\begin{equation*}
    r = \neg x \wedge y
\end{equation*}

And can be shown in this table:
\begin{center}
    \begin{tabular}{|c c|c|}
        \hline
        $x$ & $y$ & $r$ \\ \hline
        0 & 0 & 0 \\ \hline
        0 & 1 & 1 \\ \hline
        1 & 0 & 0 \\ \hline
        1 & 1 & 0 \\ \hline
    \end{tabular}
\end{center}

In the same way that we had a ripple carry adder, we can have an $n$-bit
comparison. For a 3-bit number, for them to be equal, every single bit
must match. Therefore, if we first compare the first bits, and or this
with the second bits, and or this with the third bits, this will give us
the result we require.

If we wanted to do a cyclic less-than comparison, we could do something
like O

\end{document}
